GENETIC ALGORITHMS
3
• Canon (1932) was probably the first to understand evolution as a
learning mechanism completely different to the ones performed
by individuals which are mostly based on trial and error.
• Notice that humans are able to learn because, in fact, we belong
to a class of “computing machines” capable of doing so and that
this ability is just the resuld of evolution.
• Turing (1950) also noted the “obvious connection between
machine learning and evolution”, envisioning the use of
principles of evolution in the construction of thinking machines.
• Evolutionay algorithms are a powerful alternative way to
understand learning and they offer an alternative where classic
techniques such as gradient descent or purely random search
have proven unsatisfactory.
• Genetic Algorithms (GA) are heuristic search techniques based
on the principles of natural evolution which were enunciated by
Darwin in The Origin of Species in 1859.
• According to such principles, natural selection stablishes a link
between the performance of the living beings and the
chomosomes that encode their genetic information.
• The process of natural selection has the result that chromosomes
which encode successful characteristics to reproduce more
frequently than those who do not.
4
• GA were fist proposed by Holland in 1962 but only after 1975
with the publication of his book Adaptation in Natural and
Artificial Systems they became relatively popular.
• Other proposals such as Evolutionary Programming (Fogel et al,
1966), Evolution Strategies (Rechenberg, 1971; Schewefel, 1974)
or, more recently, Genetic Programming (Koza, 1992) share
similar ideas consisting on applying principles of Evolution to the
solution of general problems.
• Similarly as with other ML techiniques such as ANNs, GAs are just
algorithmic abstractions with few or no relationship with the real
processes they emulate.
5
6
• Notice that in all the algorithms previously seen, the modification of
the solution is done directly.
• Contrary to this, Evolution is a biological process that operates on
the chromosomes rather than on their biological expression (the
living beign they encode)
• In contrast, GA operate on coded versions of the solutions, this is a
paramount diference of GAs, one of its strenghts but also one of its
drawbacks.
• In effect, since encoding is so important, the performance of the
algorith strongly depends on finding such ecoding that support
easily the search procedures.
• Encoding is, in the words of some practitioners, more an art than a
science and it car reveal or destroy the power of GA.
7
• Another important diference of GA aganist more
“clasical”
procedures is that GA are inherently parallel.
• Most of the algorithms try to find improved versions of an initial
solution while GA search for a whole set of better solutions.
• In this sense, GA implement not only a search in depth but also a
search in breadth.
• For GAs it is not essential to find, at some iteration, a solution that it
is better than the previous one but to find one set of solutions
which, globaly, are better than the preceeding.
8
• GA fall under the class of heuristic algorithms, even though some
convergence results exist, it can not be generally demonstrated that
they converge to the global (or even local) optimum.
• Nevertheless they have show their flexibility and power in many
applications that range from Finance to Electronics.
• GA are also robust and accept post-optimality analyses in a natural
fashion: when the objective function changes significant parts of the
algorithms are reusable, in contrats with other methods that require
a full re-writting of the procedures and code.
• Finally, as we shall see, GA are non deterministic but stochastic, i.e.
every time they are run on a particular problem they can provide
different solutions
• In its most basic form GA employ three operators: Selection,
Crossover and Mutation.
• These operators mimic the ones found in Genetics, which is also
the source for many other operators: diplodism, parasitism,
elitism, etc.
• GA are conceptually very simple and can be better explained
with a simple example taken from (Goldberg, 1996).
• In what follows, tet us assume we want to solve the following
trivial problem
Max x2
s.t. x = 1, 2, 3, 4…., 32
9
• The algorithm starts by taking an initial population of candidate
solutions,e.g. {1, 3, 8, 5}, these solutions can be generated by
random sampling along the space of feasible values.
• Every individual in this initial and subsequent populations is
evaluated according to some fitness function that represents how
well the solutions solves the problem at hand, how well the
“individual” is suited to the “environment”.
• Fitness functions do not need to be the same as the objective
function to be solved but, for simplicity, we will assume such case.
• Notice, then, that the fitness of each of the individuals in the
initial population are:
F(1) = 12 =1, F(3) = 32 =9, F(8) = 82 =64, F(5) = 52 =25
10
• One important characteristic of GAs is , precisely, that they only
employ information coming from the fitness function, that is, GA
do not employ any functional property of the objectve function
such as whether the function is continuous, derivable, etc.
• This is a very powerful characteristic of GA in situations where
performance can be measured but there is no
“hint” of the
specific structure of the objective function
• For example, we may know the ratings of products of some
consumers but we do not actually know which funtctions they
employ to rate them or even which characteristics of the products
are taken into account.
11
• The fistness unction is evaluated on the phenotype of the individual,
which are just the observable characteristics or traits of the
individual (e.g. height in humans).
• Genetics have to do mostly with the genotype, that is the way the
specimen is genetically encoded.
• The genotype is the most important factor to determine the
phenotype, that is, most of the appeareance of the individual
depends on its genetic econding
• The human genome is encoded in an alphabet that employs four
chemical basis: Adenyne (A), Thymine (T), Guanyne (G) and Cytosine
(C).
12
13
• Returning to the description of a basic GA, in Algorithmics, it is very
common to use the binary alphabet, there are many forms to
encode any information and, particularly, numbers in binary code,
for our example is enough to consider teh decomposition f the
number in powers of 2 and then using the indicator function of the
correponding power, ie.:
8 = 0 × 25 + 0 × 24 + 1 × 23 + 0 × 22+ 0 × 21 + 0 × 20 ≈ 001000
5 = 0 × 25 + 0 × 24 + 0 × 23 + 1 × 22+ 0 × 21 + 1 × 20 ≈ 000101
3 = 0 × 25 + 0 × 24 + 0 × 23 + 0 × 22+ 1× 21 + 1 × 20 ≈ 000011
1= 0 × 25 + 0 × 24 + 0 × 23 + 0 × 22+ 0 × 21+ 1 × 20 ≈ 000001
• The process of transforming the phenotype into the genotype is
called encoding.
13
x = ai
2i−1
i=0
n
∑ , ai ∈{0,1}
14
• In many situations portions of the encoded individual suposedly
encapsulate characteristics that are important to solve a particular
task, for example, we may think that some variabes of the objectve
funcion should have some paricular value so that the encoded
solution should be a specific string.
• Not only that, notice that the encoded version should correctly
represent epistasis, i.e. when some particular string happen in the
coded version of the individual then other particular string should
also happen so that modifiying any of the strings will have to be
followed by the modification.
• Only in this way we ensure that the decoded version has some
interpretation: for example, when a variable is equal to zero another
one should also be equal to zero.
• The need that enconding conserves the “meaning” of the decoded
versions make encoding extremelly important in the application of
Gas. 14
• The first operator of GA is called selection, in selection indiviuals
better adapated to the environment (with the highest values of
their fitness fucntions) have a higher probability ot “survive” and
to transmit their genetic information to their offsprings.
• In GA this procedure is implemented by calculating a probability
to each ones of the individuals depending on it s corresponding
fitness so that a higher fitness is corresponded by a higher
probability.
• One trivial way is to divide the fitness of the individual by the
fitness of the population of n individuals:
15
p(individual(i))=
fitness(individual(i))
fitness(individual(i))
i=1
n
∑
• Notice that in some settings it should be needed some
transformation of the fitness function to provide positive values.
• Also note that the above function fulfills the requirements to be a
probability since it is positive, bounded and sums one.
• The preceedig implementation of selection is called roulette
wheel selection and, as we will see, there are possible
modifications to this schema.
16
• In our example
• So
• Now, the mechanism of selection involves random sampling
from the abpve probability to select individuals to reproduce.
• Let us assume that we select two “parents” from the above
distribution by sampling two times.
17
fitness(individual(i))
i=1
n
∑ =1= 9 + 25+ 64 = 99
p(1)=
1
99
≈1% p(8)=
64
99 p(3)= ≈ 65% 9
99
≈ 9% p(5)=
25
99
≈ 25%
“Mother”: 8 (65%) ≈ 001000
“Father” : 3 (9%) ≈ 000011
1%
9%
65% 35%
18
• The next basic GA operator is crossover (also called
recombination) it consists in the exchange of genetic information
bewtween the “mother” and the “father”.
• To do this we first select one random crossover point that will
serve to divide the encoded chain and then exchange the subchains of father and mother to create a new individual
“Mother” (8) ≈ 001000
“Father” (3) ≈ 000011
“Offspring” ≈ 001011 è 11 (decoded)
19
• The last basic operator is mutation, it consists on randomfly
flipping one of the positions of the genetic sequence of the
offspring, e.g.
Before Mutation ≈ 001011
After Mutation ≈ 001111
• Mutation is performed using an extremelly low probability,
otherwise all the structure created y the GA would be destroyed
and the procedure would be equivalent to random search.
• Notice also that mutation is essential to avoid populations
getting “stuck” (no new offsprings can be created), e.g.:
{001000, 001000, 001000,….., 001000}
With mutation ≈ 001001
20
• Notice that selection, crossover and mutation can be applied to
create a whole new generation of offsprings and not a single one.
• When we do that, we can replace the “old” generation of
individuals by a “new” one which, hopefully, will exhibit a better
behaviour.
• Notice that, in fact, the best solution of the new
“generation” is not
necessarily better than the previous one, we just require that,
overall, the whole population is better.
21
• All the steps mentioned will be repeated until the algorithm
provides some solution with the desired level of quality or until the
improvements in the objectve funcion are not signifficant.
• A GA algorithm will run like this:
Step 1: Generate an initial random poulation
Step 2: Codify the solutions
Step3: Evaluate the fitness of each of the
individuals, stop if
optimality is achieved
Step 4: Perform selection
Step 5: Perform crossover
Step 6: Perform mutation
Step 7: Go to step 3
22
• The following table summarizes the relationships between some
biological concepts and their interpretation in GA optimization.
23
Biological Inspired Concept Genetic Algorithm Optimization
Fitness Objective Function
Individual Solution
Generation Iteration
Phenotype Decoded Solution
Genotype Encoded Solution
Gene Binary string
